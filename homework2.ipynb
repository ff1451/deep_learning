{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9baf791",
   "metadata": {},
   "source": [
    "### [요구사항 1] titanic 딥러닝 모델 기본 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79586684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251016_201727-wnmggzzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/wnmggzzc' target=\"_blank\">2025-10-16_20-17-27</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/wnmggzzc' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/wnmggzzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, batch_size=512, epochs=1000)\n",
      "{'epochs': 1000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n",
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x3321b92b0> <torch.utils.data.dataset.Subset object at 0x3321ba090> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5998, Validation loss 0.5515\n",
      "Epoch 200, Training loss 0.5908, Validation loss 0.5408\n",
      "Epoch 300, Training loss 0.5894, Validation loss 0.5362\n",
      "Epoch 400, Training loss 0.5858, Validation loss 0.5326\n",
      "Epoch 500, Training loss 0.5953, Validation loss 0.5320\n",
      "Epoch 600, Training loss 0.5898, Validation loss 0.5276\n",
      "Epoch 700, Training loss 0.5689, Validation loss 0.5245\n",
      "Epoch 800, Training loss 0.5729, Validation loss 0.5211\n",
      "Epoch 900, Training loss 0.5827, Validation loss 0.5211\n",
      "Epoch 1000, Training loss 0.5842, Validation loss 0.5206\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▆▇▄▅▄▄▃▂▃▃▃▂▂▄▂▃▃▃▃▂▂▂▄▃▃▄▁▂▂▂▃▁▃▃▂▄▄▃▁</td></tr><tr><td>Validation loss</td><td>█▆▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.58417</td></tr><tr><td>Validation loss</td><td>0.52056</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-16_20-17-27</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/wnmggzzc' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/wnmggzzc</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_201727-wnmggzzc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "# 경로 설정 및 데이터셋 로드\n",
    "# Titanic 데이터셋 이진 분류 문제\n",
    "# BASE_PATH를 sys.path에 추가하여 커스텀 모듈 import 가능\n",
    "\n",
    "BASE_PATH = \"/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl\"\n",
    "if BASE_PATH not in sys.path:\n",
    "    sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "# DataLoader 생성 함수\n",
    "# 훈련과 검증 데이터셋을 불러옴\n",
    "# batch_size는 wandb 설정에서 받아옴\n",
    "\n",
    "def get_data():\n",
    "  titanic_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(titanic_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=titanic_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader\n",
    "\n",
    "# 모델 정의\n",
    "# 입력 : 10개 feature (전처리된 Titanic 데이터셋)\n",
    "# 출력 : 2개 클래스 (사망 / 생존)\n",
    "# 활성화 함수 : ReLU\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# 모델 및 옵티마이저 생성\n",
    "# optimizer : SGD\n",
    "# loss_fn은 training_loop 내에서 정의하고 있음\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "# 학습 루프\n",
    "# 손실 함수 : CrossEntropyLoss : 타이타닉의 경우 생존, 사망 두가지로 분류되므로 분류 모델 사용\n",
    "# wandb로 학습 과정 로깅\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input = train_batch['input']\n",
    "      target = train_batch['target']\n",
    "\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input = validation_batch['input']\n",
    "        target = validation_batch['target']\n",
    "\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    #wandb 로깅\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "# main 함수\n",
    "# wandb, experiment 초기화\n",
    "# 데이터, 모델, 학습 루프 실행\n",
    "\n",
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [20, 20],\n",
    "  }\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=\"my_model_training\",\n",
    "    notes=\"My first wandb experiment\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=current_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  in_notebook = \"ipykernel\" in sys.modules\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=in_notebook, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=512, help=\"Batch size (int, default: 512)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=1_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args, _ = parser.parse_known_args()\n",
    "\n",
    "  main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dab82a",
   "metadata": {},
   "source": [
    "##### 기술적 사항\n",
    "- 데이터셋 : Titanic\n",
    "  - 타깃 값(survived)이 0 또는 1인 이진 분류 문제\n",
    "  - 결측값 처리 및 범주형으로 전처리 완료\n",
    "- 모델 구조\n",
    "  - 입력 차원: 10\n",
    "  - 은닉층: 20 -> 20 (ReLU 활성화)\n",
    "  - 출력 차원 : 2 (사망/생존)\n",
    "- 손실 함수 : CrossEntropyLoss\n",
    "  - 확률 기반 분류 문제에 적합\n",
    "- Optimizer : SGD\n",
    "- Batch Size: 512\n",
    "- Epochs : 1000\n",
    "\n",
    "##### 고찰\n",
    "- CrossEntropyLoss와 MSELoss 차이\n",
    "  - MSELoss는 회귀(연속값)에 적합, CrossEntropyLoss는 분류(클래스)에 적합\n",
    "  - CrossEntropyLoss는 클래스 확률을 직접 최적화하기 때문에 분류 문제에서 더 빠르고 안정적인 수렴을 보임\n",
    "\n",
    "- optimize의 역할\n",
    "  - SGD는 간단하면서도 안정적인 기본 옵티마이저임\n",
    "  - 이후 성능 향상을 위해 Adam으로 변경해볼 수 있음\n",
    "\n",
    "- 학습률의 중요성\n",
    "  - 너무 높으면 발산\n",
    "  - 너무 낮으면 수렴이 느려짐\n",
    "  - 현재는 0.001로 안정적인 학습이 이루어짐\n",
    "\n",
    "##### 결과 해석\n",
    "- Training Loss, Validation Loss 차이\n",
    "  - 두 값이 큰 차이 없이 비슷하게 감소하고 있음\n",
    "    - 과적합 징후가 거의 없음을 확인 가능\n",
    "    - 현재 학습률 설정이 안정적임\n",
    "\n",
    "- 700 epoch 이후 손실 감소 폭이 작아짐\n",
    "  - Validation loss가 0.52 근처에서 수렴\n",
    "  - 현재 설정으로는 모델이 더 이상 성능 향상을 크게 이루지 못하는 상태\n",
    "\n",
    "- Validation Loss가 Train Loss보다 낮거나 거의 같은 구간 존재\n",
    "  - 흔히 regularization이 잘 된 경우 이런 현상이 발생함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbfab6",
   "metadata": {},
   "source": [
    "### [요구사항 2] Activation Function과 Batch Size 변경 및 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b5780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/link_dl/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/link_dl/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mff1451\u001b[0m (\u001b[33mff1451-korea-university-of-technology-and-education\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001903-6umsdlql</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6umsdlql' target=\"_blank\">2025-10-17_00-19-02-act=relu-bs=512</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6umsdlql' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6umsdlql</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, activation='relu', batch_size=512, epochs=1000)\n",
      "{'epochs': 1000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20], 'activation': 'relu', 'group': 'act_vs_batch'}\n",
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x3265ff380> <torch.utils.data.dataset.Subset object at 0x3265f6d50> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.6171, Validation loss 0.6251\n",
      "Epoch 200, Training loss 0.6121, Validation loss 0.6176\n",
      "Epoch 300, Training loss 0.6067, Validation loss 0.6154\n",
      "Epoch 400, Training loss 0.6141, Validation loss 0.6149\n",
      "Epoch 500, Training loss 0.5923, Validation loss 0.6146\n",
      "Epoch 600, Training loss 0.5926, Validation loss 0.6140\n",
      "Epoch 700, Training loss 0.6056, Validation loss 0.6126\n",
      "Epoch 800, Training loss 0.5982, Validation loss 0.6134\n",
      "Epoch 900, Training loss 0.6063, Validation loss 0.6138\n",
      "Epoch 1000, Training loss 0.6000, Validation loss 0.6120\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>Training loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▁▁▂▂▁▂▂▁▂▁▁▂▁▂▁▁▂▁▂</td></tr><tr><td>Validation loss</td><td>█▆▄▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.59998</td></tr><tr><td>Validation loss</td><td>0.61197</td></tr><tr><td>hparams/activation</td><td>relu</td></tr><tr><td>hparams/batch_size</td><td>512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-17_00-19-02-act=relu-bs=512</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6umsdlql' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6umsdlql</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001903-6umsdlql/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001911-59ey9fzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/59ey9fzx' target=\"_blank\">act=relu-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/59ey9fzx' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/59ey9fzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329b92990> <torch.utils.data.dataset.Subset object at 0x329bcdba0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5692, Validation loss 0.5496\n",
      "Epoch 200, Training loss 0.5444, Validation loss 0.5198\n",
      "Epoch 300, Training loss 0.5104, Validation loss 0.4841\n",
      "Epoch 400, Training loss 0.4787, Validation loss 0.4534\n",
      "Epoch 500, Training loss 0.4543, Validation loss 0.4624\n",
      "Epoch 600, Training loss 0.4383, Validation loss 0.4595\n",
      "Epoch 700, Training loss 0.4364, Validation loss 0.5232\n",
      "Epoch 800, Training loss 0.4299, Validation loss 0.5421\n",
      "Epoch 900, Training loss 0.4452, Validation loss 0.4851\n",
      "Epoch 1000, Training loss 0.4181, Validation loss 0.4704\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▃▃▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>█▇▇▇▇▆▆▆▆▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁</td></tr><tr><td>Validation loss</td><td>██▇▇▇▆▆▆▇▅▅▆▄▄▄▃▃▃▃▃▆▂▃▃▃▇▂▃▂▂▃▂▁▄▂▃▂▃▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.41807</td></tr><tr><td>Validation loss</td><td>0.4704</td></tr><tr><td>hparams/activation</td><td>relu</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=relu-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/59ey9fzx' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/59ey9fzx</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001911-59ey9fzx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001928-hsn7kfc1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hsn7kfc1' target=\"_blank\">act=relu-bs=32</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hsn7kfc1' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hsn7kfc1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329bcf100> <torch.utils.data.dataset.Subset object at 0x329e88950> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5905, Validation loss 0.6350\n",
      "Epoch 200, Training loss 0.5877, Validation loss 0.6300\n",
      "Epoch 300, Training loss 0.5780, Validation loss 0.6240\n",
      "Epoch 400, Training loss 0.5738, Validation loss 0.6097\n",
      "Epoch 500, Training loss 0.5620, Validation loss 0.5946\n",
      "Epoch 600, Training loss 0.5398, Validation loss 0.5804\n",
      "Epoch 700, Training loss 0.5424, Validation loss 0.5636\n",
      "Epoch 800, Training loss 0.5157, Validation loss 0.5665\n",
      "Epoch 900, Training loss 0.4831, Validation loss 0.5238\n",
      "Epoch 1000, Training loss 0.4820, Validation loss 0.4872\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>█▇▇▆▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▄▃▂▂▂▂▂▂▁</td></tr><tr><td>Validation loss</td><td>████████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▃▃▃▃▄▃▂▄▃▄▃▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.48197</td></tr><tr><td>Validation loss</td><td>0.48717</td></tr><tr><td>hparams/activation</td><td>relu</td></tr><tr><td>hparams/batch_size</td><td>32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=relu-bs=32</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hsn7kfc1' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hsn7kfc1</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001928-hsn7kfc1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001940-bxh9eep0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/bxh9eep0' target=\"_blank\">act=relu-bs=64</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/bxh9eep0' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/bxh9eep0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329dcd040> <torch.utils.data.dataset.Subset object at 0x329dcd480> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5843, Validation loss 0.5516\n",
      "Epoch 200, Training loss 0.5826, Validation loss 0.5368\n",
      "Epoch 300, Training loss 0.5662, Validation loss 0.5326\n",
      "Epoch 400, Training loss 0.5833, Validation loss 0.6973\n",
      "Epoch 500, Training loss 0.5559, Validation loss 0.5212\n",
      "Epoch 600, Training loss 0.5383, Validation loss 0.5066\n",
      "Epoch 700, Training loss 0.5399, Validation loss 0.5180\n",
      "Epoch 800, Training loss 0.5301, Validation loss 0.5437\n",
      "Epoch 900, Training loss 0.5216, Validation loss 0.4880\n",
      "Epoch 1000, Training loss 0.5404, Validation loss 0.4605\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▅▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▃▂▂▂▂▁▂▂▁▂▂▁▂</td></tr><tr><td>Validation loss</td><td>▆▆▆▆▇▅▇▆▅▅▅▅▄▄▄▄▄▄▅▅▄▃▃▃▃▃▅▂▂█▅▂▁▁▂▁▁▃▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.54045</td></tr><tr><td>Validation loss</td><td>0.46053</td></tr><tr><td>hparams/activation</td><td>relu</td></tr><tr><td>hparams/batch_size</td><td>64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=relu-bs=64</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/bxh9eep0' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/bxh9eep0</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001940-bxh9eep0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001949-9scbhaxw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/9scbhaxw' target=\"_blank\">act=relu-bs=128</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/9scbhaxw' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/9scbhaxw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329d9a350> <torch.utils.data.dataset.Subset object at 0x329d9ad50> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5920, Validation loss 0.5941\n",
      "Epoch 200, Training loss 0.5931, Validation loss 0.5973\n",
      "Epoch 300, Training loss 0.5850, Validation loss 0.5889\n",
      "Epoch 400, Training loss 0.5838, Validation loss 0.5952\n",
      "Epoch 500, Training loss 0.5783, Validation loss 0.5877\n",
      "Epoch 600, Training loss 0.5797, Validation loss 0.5881\n",
      "Epoch 700, Training loss 0.5829, Validation loss 0.5879\n",
      "Epoch 800, Training loss 0.5717, Validation loss 0.5899\n",
      "Epoch 900, Training loss 0.5754, Validation loss 0.5919\n",
      "Epoch 1000, Training loss 0.5682, Validation loss 0.5901\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▇▅▄▄▄▃▃▃▃▃▃▄▃▃▂▃▃▃▃▃▃▃▃▃▂▁▁▂▃▂▂▂▂▁▂▂▂▂▁</td></tr><tr><td>Validation loss</td><td>█▇▄▆▆▃▆▄▄▇▅▅▄▅▇▄▆▅▄▄▄▄▄▃▁▂▄▄▅▃▃▃▄▃▃▄▅▁▅█</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.56823</td></tr><tr><td>Validation loss</td><td>0.59011</td></tr><tr><td>hparams/activation</td><td>relu</td></tr><tr><td>hparams/batch_size</td><td>128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=relu-bs=128</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/9scbhaxw' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/9scbhaxw</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001949-9scbhaxw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_001957-o5jmud6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/o5jmud6x' target=\"_blank\">act=sigmoid-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/o5jmud6x' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/o5jmud6x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x3203585f0> <torch.utils.data.dataset.Subset object at 0x329dc3a70> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.6414, Validation loss 0.6676\n",
      "Epoch 200, Training loss 0.6270, Validation loss 0.6570\n",
      "Epoch 300, Training loss 0.6115, Validation loss 0.6481\n",
      "Epoch 400, Training loss 0.5997, Validation loss 0.6422\n",
      "Epoch 500, Training loss 0.5952, Validation loss 0.6392\n",
      "Epoch 600, Training loss 0.5902, Validation loss 0.6375\n",
      "Epoch 700, Training loss 0.5884, Validation loss 0.6365\n",
      "Epoch 800, Training loss 0.5847, Validation loss 0.6354\n",
      "Epoch 900, Training loss 0.5841, Validation loss 0.6339\n",
      "Epoch 1000, Training loss 0.5813, Validation loss 0.6341\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Training loss</td><td>█▇▇▇▇▆▇▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>█▇▇▇▇▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.5813</td></tr><tr><td>Validation loss</td><td>0.63412</td></tr><tr><td>hparams/activation</td><td>sigmoid</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=sigmoid-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/o5jmud6x' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/o5jmud6x</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_001957-o5jmud6x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002014-y0thoxof</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/y0thoxof' target=\"_blank\">act=sigmoid-bs=32</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/y0thoxof' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/y0thoxof</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329ed0050> <torch.utils.data.dataset.Subset object at 0x329ed1fd0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.6611, Validation loss 0.6545\n",
      "Epoch 200, Training loss 0.6539, Validation loss 0.6439\n",
      "Epoch 300, Training loss 0.6506, Validation loss 0.6340\n",
      "Epoch 400, Training loss 0.6433, Validation loss 0.6242\n",
      "Epoch 500, Training loss 0.6331, Validation loss 0.6149\n",
      "Epoch 600, Training loss 0.6269, Validation loss 0.6060\n",
      "Epoch 700, Training loss 0.6271, Validation loss 0.5978\n",
      "Epoch 800, Training loss 0.6218, Validation loss 0.5906\n",
      "Epoch 900, Training loss 0.6156, Validation loss 0.5851\n",
      "Epoch 1000, Training loss 0.6184, Validation loss 0.5803\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>██▇▇▇▇▆▇▆▆▆▅▆▅▅▅▅▅▄▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▂▁</td></tr><tr><td>Validation loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.61844</td></tr><tr><td>Validation loss</td><td>0.58025</td></tr><tr><td>hparams/activation</td><td>sigmoid</td></tr><tr><td>hparams/batch_size</td><td>32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=sigmoid-bs=32</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/y0thoxof' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/y0thoxof</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002014-y0thoxof/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002026-pf0h5n9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/pf0h5n9j' target=\"_blank\">act=sigmoid-bs=64</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/pf0h5n9j' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/pf0h5n9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329ed6b60> <torch.utils.data.dataset.Subset object at 0x31f3744d0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.6690, Validation loss 0.6343\n",
      "Epoch 200, Training loss 0.6597, Validation loss 0.6326\n",
      "Epoch 300, Training loss 0.6679, Validation loss 0.6306\n",
      "Epoch 400, Training loss 0.6589, Validation loss 0.6285\n",
      "Epoch 500, Training loss 0.6560, Validation loss 0.6257\n",
      "Epoch 600, Training loss 0.6514, Validation loss 0.6231\n",
      "Epoch 700, Training loss 0.6479, Validation loss 0.6199\n",
      "Epoch 800, Training loss 0.6364, Validation loss 0.6177\n",
      "Epoch 900, Training loss 0.6345, Validation loss 0.6159\n",
      "Epoch 1000, Training loss 0.6343, Validation loss 0.6114\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>▆▇█▇▆▆▆▆▆▆▆▆▆▆▅▅▆▅▅▆▅▄▅▅▆▅▅▅▄▄▆▄▃▃▃▂▂▃▁▂</td></tr><tr><td>Validation loss</td><td>█▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.63432</td></tr><tr><td>Validation loss</td><td>0.61143</td></tr><tr><td>hparams/activation</td><td>sigmoid</td></tr><tr><td>hparams/batch_size</td><td>64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=sigmoid-bs=64</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/pf0h5n9j' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/pf0h5n9j</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002026-pf0h5n9j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002035-as0a5xt4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/as0a5xt4' target=\"_blank\">act=sigmoid-bs=128</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/as0a5xt4' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/as0a5xt4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f375a90> <torch.utils.data.dataset.Subset object at 0x329b1bcd0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.6637, Validation loss 0.6639\n",
      "Epoch 200, Training loss 0.6580, Validation loss 0.6616\n",
      "Epoch 300, Training loss 0.6558, Validation loss 0.6600\n",
      "Epoch 400, Training loss 0.6618, Validation loss 0.6583\n",
      "Epoch 500, Training loss 0.6584, Validation loss 0.6565\n",
      "Epoch 600, Training loss 0.6554, Validation loss 0.6546\n",
      "Epoch 700, Training loss 0.6511, Validation loss 0.6527\n",
      "Epoch 800, Training loss 0.6509, Validation loss 0.6506\n",
      "Epoch 900, Training loss 0.6516, Validation loss 0.6485\n",
      "Epoch 1000, Training loss 0.6500, Validation loss 0.6462\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▅▅▄▄▃▃▃▄▃▃▂▃▃▃▃▃▃▃▃▃▂▃▃▁▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>█▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.65001</td></tr><tr><td>Validation loss</td><td>0.64623</td></tr><tr><td>hparams/activation</td><td>sigmoid</td></tr><tr><td>hparams/batch_size</td><td>128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=sigmoid-bs=128</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/as0a5xt4' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/as0a5xt4</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002035-as0a5xt4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002042-rmasffa5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/rmasffa5' target=\"_blank\">act=elu-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/rmasffa5' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/rmasffa5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f307d80> <torch.utils.data.dataset.Subset object at 0x329dfe0d0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5681, Validation loss 0.6829\n",
      "Epoch 200, Training loss 0.5353, Validation loss 0.5441\n",
      "Epoch 300, Training loss 0.4926, Validation loss 0.5146\n",
      "Epoch 400, Training loss 0.4821, Validation loss 0.4766\n",
      "Epoch 500, Training loss 0.4591, Validation loss 0.4791\n",
      "Epoch 600, Training loss 0.4698, Validation loss 0.5125\n",
      "Epoch 700, Training loss 0.4347, Validation loss 0.4581\n",
      "Epoch 800, Training loss 0.4447, Validation loss 0.4451\n",
      "Epoch 900, Training loss 0.4379, Validation loss 0.4563\n",
      "Epoch 1000, Training loss 0.4317, Validation loss 0.4718\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▇▇▇▇▇▇██</td></tr><tr><td>Training loss</td><td>█▇▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▃▂▃▃▃▂▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>█▆▅▅▅▄▄▄▄▃▃▃▂▂▄▂▃▃▆▅▂▂▁▃▂▂▂▂▃▂▁▂▂▂▁▃▂▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.43168</td></tr><tr><td>Validation loss</td><td>0.47179</td></tr><tr><td>hparams/activation</td><td>elu</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=elu-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/rmasffa5' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/rmasffa5</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002042-rmasffa5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002101-3cfgqbtg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/3cfgqbtg' target=\"_blank\">act=elu-bs=32</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/3cfgqbtg' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/3cfgqbtg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x3267e5b30> <torch.utils.data.dataset.Subset object at 0x329dfbbf0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5784, Validation loss 0.6073\n",
      "Epoch 200, Training loss 0.5693, Validation loss 0.5948\n",
      "Epoch 300, Training loss 0.5541, Validation loss 0.5847\n",
      "Epoch 400, Training loss 0.5403, Validation loss 0.5835\n",
      "Epoch 500, Training loss 0.5271, Validation loss 0.5746\n",
      "Epoch 600, Training loss 0.5117, Validation loss 0.5729\n",
      "Epoch 700, Training loss 0.4986, Validation loss 0.5228\n",
      "Epoch 800, Training loss 0.5378, Validation loss 0.5026\n",
      "Epoch 900, Training loss 0.4866, Validation loss 0.4995\n",
      "Epoch 1000, Training loss 0.4480, Validation loss 0.5640\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>Training loss</td><td>█▆▆▅▅▅▅▅▅▅▄▄▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▁▃▂▁</td></tr><tr><td>Validation loss</td><td>█▇▇▇▇▇▆▅▆▅▆▅▅▆▅▅▅▄▅▄▆▅▄▄▅▄▄▆▆▄▄▃▂▂▂▂▁▂▂▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.448</td></tr><tr><td>Validation loss</td><td>0.56398</td></tr><tr><td>hparams/activation</td><td>elu</td></tr><tr><td>hparams/batch_size</td><td>32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=elu-bs=32</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/3cfgqbtg' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/3cfgqbtg</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002101-3cfgqbtg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002113-mjv0uthw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/mjv0uthw' target=\"_blank\">act=elu-bs=64</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/mjv0uthw' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/mjv0uthw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329e272d0> <torch.utils.data.dataset.Subset object at 0x31f37fbd0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5788, Validation loss 0.6154\n",
      "Epoch 200, Training loss 0.5620, Validation loss 0.5899\n",
      "Epoch 300, Training loss 0.5533, Validation loss 0.5702\n",
      "Epoch 400, Training loss 0.5425, Validation loss 0.6088\n",
      "Epoch 500, Training loss 0.5272, Validation loss 0.5658\n",
      "Epoch 600, Training loss 0.5163, Validation loss 0.5352\n",
      "Epoch 700, Training loss 0.4972, Validation loss 0.5692\n",
      "Epoch 800, Training loss 0.5125, Validation loss 0.5747\n",
      "Epoch 900, Training loss 0.4878, Validation loss 0.5158\n",
      "Epoch 1000, Training loss 0.4553, Validation loss 0.5609\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>█▆▆▆▆▆▇▅▆▆▆▆▅▅▄▅▄▅▅▄▄▄▄▄▃▄▅▃▃▃▃▄▃▂▂▂▂▂▁▂</td></tr><tr><td>Validation loss</td><td>▄▄▃▃▃▃▃▂▃▃▃▃▂▂▂▂▃▂▂▂▃▂▂▁▂▂▂▃▁▂▁▁▂▂▂▄▁▂▅█</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.45535</td></tr><tr><td>Validation loss</td><td>0.56089</td></tr><tr><td>hparams/activation</td><td>elu</td></tr><tr><td>hparams/batch_size</td><td>64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=elu-bs=64</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/mjv0uthw' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/mjv0uthw</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002113-mjv0uthw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002122-vrtdnbbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/vrtdnbbk' target=\"_blank\">act=elu-bs=128</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/vrtdnbbk' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/vrtdnbbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329e69240> <torch.utils.data.dataset.Subset object at 0x329e6ac10> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.6007, Validation loss 0.6329\n",
      "Epoch 200, Training loss 0.5858, Validation loss 0.6249\n",
      "Epoch 300, Training loss 0.5841, Validation loss 0.6221\n",
      "Epoch 400, Training loss 0.5867, Validation loss 0.6210\n",
      "Epoch 500, Training loss 0.5830, Validation loss 0.6201\n",
      "Epoch 600, Training loss 0.5783, Validation loss 0.6182\n",
      "Epoch 700, Training loss 0.5798, Validation loss 0.6171\n",
      "Epoch 800, Training loss 0.5745, Validation loss 0.6150\n",
      "Epoch 900, Training loss 0.5766, Validation loss 0.6127\n",
      "Epoch 1000, Training loss 0.5664, Validation loss 0.6102\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>Training loss</td><td>█▆▄▄▃▄▃▄▃▃▂▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁</td></tr><tr><td>Validation loss</td><td>█▇▆▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.5664</td></tr><tr><td>Validation loss</td><td>0.61019</td></tr><tr><td>hparams/activation</td><td>elu</td></tr><tr><td>hparams/batch_size</td><td>128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=elu-bs=128</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/vrtdnbbk' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/vrtdnbbk</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002122-vrtdnbbk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002129-run19guv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/run19guv' target=\"_blank\">act=leakyrelu-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/run19guv' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/run19guv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f387110> <torch.utils.data.dataset.Subset object at 0x31f385850> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5895, Validation loss 0.5329\n",
      "Epoch 200, Training loss 0.5712, Validation loss 0.5269\n",
      "Epoch 300, Training loss 0.5540, Validation loss 0.4960\n",
      "Epoch 400, Training loss 0.5257, Validation loss 0.4777\n",
      "Epoch 500, Training loss 0.4889, Validation loss 0.4265\n",
      "Epoch 600, Training loss 0.4698, Validation loss 0.4173\n",
      "Epoch 700, Training loss 0.4411, Validation loss 0.4054\n",
      "Epoch 800, Training loss 0.4299, Validation loss 0.4012\n",
      "Epoch 900, Training loss 0.4449, Validation loss 0.5198\n",
      "Epoch 1000, Training loss 0.4386, Validation loss 0.3909\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Training loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▆▅▅▅▅▄▃▃▃▂▃▃▃▃▃▂▃▂▂▂▁▁▂</td></tr><tr><td>Validation loss</td><td>▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.43863</td></tr><tr><td>Validation loss</td><td>0.39086</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=leakyrelu-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/run19guv' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/run19guv</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002129-run19guv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002147-6m0hy8h9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6m0hy8h9' target=\"_blank\">act=leakyrelu-bs=32</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6m0hy8h9' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6m0hy8h9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f3431d0> <torch.utils.data.dataset.Subset object at 0x31f343dd0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5833, Validation loss 0.5819\n",
      "Epoch 200, Training loss 0.5788, Validation loss 0.5825\n",
      "Epoch 300, Training loss 0.5689, Validation loss 0.5609\n",
      "Epoch 400, Training loss 0.5566, Validation loss 0.5710\n",
      "Epoch 500, Training loss 0.5228, Validation loss 0.5287\n",
      "Epoch 600, Training loss 0.4924, Validation loss 0.4991\n",
      "Epoch 700, Training loss 0.5365, Validation loss 0.5624\n",
      "Epoch 800, Training loss 0.4634, Validation loss 0.4834\n",
      "Epoch 900, Training loss 0.4359, Validation loss 0.4900\n",
      "Epoch 1000, Training loss 0.4144, Validation loss 0.5074\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇█████</td></tr><tr><td>Training loss</td><td>███▇▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▃▃▃▂▂▁▂▂▂▂▁▁▁▂▁</td></tr><tr><td>Validation loss</td><td>▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▃█▃▂▃▃▁▂▁▅▅▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.41441</td></tr><tr><td>Validation loss</td><td>0.50742</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>32</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=leakyrelu-bs=32</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6m0hy8h9' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/6m0hy8h9</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002147-6m0hy8h9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002158-hux1ret0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hux1ret0' target=\"_blank\">act=leakyrelu-bs=64</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hux1ret0' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hux1ret0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329e924b0> <torch.utils.data.dataset.Subset object at 0x329e90dd0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5866, Validation loss 0.6370\n",
      "Epoch 200, Training loss 0.5918, Validation loss 0.6345\n",
      "Epoch 300, Training loss 0.5697, Validation loss 0.6332\n",
      "Epoch 400, Training loss 0.5935, Validation loss 0.6208\n",
      "Epoch 500, Training loss 0.5640, Validation loss 0.6272\n",
      "Epoch 600, Training loss 0.5563, Validation loss 0.6262\n",
      "Epoch 700, Training loss 0.5560, Validation loss 0.6123\n",
      "Epoch 800, Training loss 0.5418, Validation loss 0.6119\n",
      "Epoch 900, Training loss 0.5570, Validation loss 0.5971\n",
      "Epoch 1000, Training loss 0.5393, Validation loss 0.5992\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▆▅▅▅▅▆▅▅▆▅▃▄▅▅▄▅▆▄▅▆▄▄▄▄▃▃▃▄▃▃▂▂▃▁▄▂▂▃▄</td></tr><tr><td>Validation loss</td><td>▇██▇▇▆▆▆▆▆▆▆▆▆▅▆▅▅▄▅▅▅▄▅▄▅▄▄▄▄▃▃▂▂▄▄▁▃▃▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.53931</td></tr><tr><td>Validation loss</td><td>0.59921</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>64</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=leakyrelu-bs=64</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hux1ret0' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/hux1ret0</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002158-hux1ret0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_002207-5pf57b5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/5pf57b5w' target=\"_blank\">act=leakyrelu-bs=128</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/5pf57b5w' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/5pf57b5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x329ee71d0> <torch.utils.data.dataset.Subset object at 0x329ee6db0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "Epoch 100, Training loss 0.5864, Validation loss 0.6076\n",
      "Epoch 200, Training loss 0.5782, Validation loss 0.6076\n",
      "Epoch 300, Training loss 0.5705, Validation loss 0.6005\n",
      "Epoch 400, Training loss 0.5609, Validation loss 0.5936\n",
      "Epoch 500, Training loss 0.5637, Validation loss 0.6198\n",
      "Epoch 600, Training loss 0.5537, Validation loss 0.5872\n",
      "Epoch 700, Training loss 0.5505, Validation loss 0.5806\n",
      "Epoch 800, Training loss 0.5478, Validation loss 0.5794\n",
      "Epoch 900, Training loss 0.5531, Validation loss 0.5764\n",
      "Epoch 1000, Training loss 0.5419, Validation loss 0.5766\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>Training loss</td><td>█▇▆▇▆▇▆▆▅▅▅▅▅▄▅▅▅▅▄▄▄▄▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▁▁</td></tr><tr><td>Validation loss</td><td>█▇▇▆▆▆▅▅▆▅▅▅▆▅▄▅▆▄▅▄▄▄▅▅▃▄▆▃▃▄▃▃▂▃▂▂▂▁▂▂</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.54191</td></tr><tr><td>Validation loss</td><td>0.5766</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">act=leakyrelu-bs=128</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/5pf57b5w' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/5pf57b5w</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_002207-5pf57b5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "# 경로 설정 및 데이터셋 로드\n",
    "# Titanic 데이터셋 이진 분류 문제\n",
    "# BASE_PATH를 sys.path에 추가하여 커스텀 모듈 import 가능\n",
    "\n",
    "BASE_PATH = \"/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl\"\n",
    "if BASE_PATH not in sys.path:\n",
    "    sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "# 활성 함수를 변경하기 위한 함수\n",
    "def get_activation(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    if name == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    if name == \"elu\":\n",
    "        return nn.ELU()\n",
    "    if name in (\"leakyrelu\", \"leaky_relu\", \"lrelu\"):\n",
    "        return nn.LeakyReLU(negative_slope=0.01)\n",
    "    raise ValueError(f\"Unknown activation: {name}\")\n",
    "\n",
    "# DataLoader 생성 함수\n",
    "# 훈련과 검증 데이터셋을 불러옴\n",
    "# batch_size는 wandb 설정에서 받아옴\n",
    "\n",
    "def get_data():\n",
    "  titanic_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(titanic_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=titanic_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "  return train_data_loader, validation_data_loader\n",
    "\n",
    "# 모델 정의\n",
    "# 입력 : 10개 feature (전처리된 Titanic 데이터셋)\n",
    "# 출력 : 2개 클래스 (사망 / 생존)\n",
    "# 활성화 함수 : wandb.config.activation 사용\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "    act = get_activation(wandb.config.activation)\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      act,\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      act,\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# 모델 및 옵티마이저 생성\n",
    "# optimizer : SGD\n",
    "# loss_fn은 training_loop 내에서 정의하고 있음\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "# 학습 루프\n",
    "# 손실 함수 : CrossEntropyLoss : 타이타닉의 경우 생존, 사망 두가지로 분류되므로 분류 모델 사용\n",
    "# wandb로 학습 과정 로깅\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input = train_batch['input']\n",
    "      target = train_batch['target']\n",
    "\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input = validation_batch['input']\n",
    "        target = validation_batch['target']\n",
    "\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    # wandb 로깅 (+ 비교용 메타 추가)\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations,\n",
    "      \"hparams/activation\": wandb.config.activation,   # ← Facet/Filter/Color 용\n",
    "      \"hparams/batch_size\": wandb.config.batch_size,   # ← Facet/Filter/Color 용\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "# main 함수\n",
    "# wandb, experiment 초기화\n",
    "# 데이터, 모델, 학습 루프 실행\n",
    "\n",
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [20, 20],\n",
    "    'activation': args.activation,     # ★ 추가: 모델이 참조하는 활성화 함수\n",
    "    'group': 'act_vs_batch',           # ★ 추가: 한 프레임에 묶어보기 위한 그룹명\n",
    "  }\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=\"my_model_training\",\n",
    "    notes=\"Activation x Batch sweep (Titanic)\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=f\"{current_time_str}-act={args.activation}-bs={args.batch_size}\",  # ★ 러닝 구분 쉬움\n",
    "    group=config['group'],                                                 # ★ 같은 그룹으로 묶기\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  in_notebook = \"ipykernel\" in sys.modules\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=in_notebook, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--activation\", type=str, default=\"relu\",\n",
    "    choices=[\"relu\", \"sigmoid\", \"elu\", \"leakyrelu\"], help=\"Hidden activation function\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=512, help=\"Batch size (int, default: 512)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=1_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args, _ = parser.parse_known_args()\n",
    "\n",
    "  main(args)\n",
    "\n",
    "\n",
    "activations = [\"relu\", \"sigmoid\", \"elu\", \"leakyrelu\"]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "\n",
    "for act in activations:\n",
    "    for bs in batch_sizes:\n",
    "        wandb.init(\n",
    "            mode=\"online\",\n",
    "            project=\"my_model_training\",\n",
    "            group=\"act_vs_batch\",\n",
    "            name=f\"act={act}-bs={bs}\",\n",
    "            config={\n",
    "                \"epochs\": 1000,\n",
    "                \"batch_size\": bs,\n",
    "                \"learning_rate\": 1e-3,\n",
    "                \"n_hidden_unit_list\": [20, 20],\n",
    "                \"activation\": act,\n",
    "                \"group\": \"act_vs_batch\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 이 아래는 실험 실행\n",
    "        train_loader, val_loader = get_data()\n",
    "        model, optimizer = get_model_and_optimizer()\n",
    "        training_loop(model, optimizer, train_loader, val_loader)\n",
    "\n",
    "        # wandb 세션 종료\n",
    "        wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2c6e6",
   "metadata": {},
   "source": [
    "##### 결과 분석\n",
    "- 제일 좋은 성능을 보인 Activation Function과 Batch Size 조합은 LeakyReLU + Batch size 16\n",
    "  - Validation loss가 0.3909로 가장 높은 성능을 보임\n",
    "\n",
    "- 그 외 상위권\n",
    "  - ReLU, 64 : 0.4605\n",
    "  - ReLU, 16 : 0.4704\n",
    "  - ELU, 16 : 0.4718\n",
    "  - ReLU, 32 : 0.4872\n",
    "\n",
    "- 평균 경향\n",
    "  - Batch size : 대체로 작을 수록 일반화 성능이 좋았음\n",
    "  - Activation : 최고점은 LeakyReLU 였지만 평균적으로는 ReLU가 가장 안정적\n",
    "  - Sigmoid: 전반적으로 가장 약한 성능을 보였음\n",
    "\n",
    "- LeakyReLU의 강점\n",
    "  - ReLU는 음수에서 기울기가 0이라 죽은 뉴런 문제 발생가능\n",
    "  - LeakyReLU는 음수 영역에 작은 기울기를 주어 표현력/수렴 안정성이 개선됨\n",
    "  - 특히 작은 배치 사이즈와 결합하면 노이즈가 적당한 정규화 효과를 내어 일반화에 유리하게 작용\n",
    "\n",
    "- 배치 사이즈의 역할\n",
    "  - 작은 배치는 Gradient에 노이즈 도입 따라서 과적합 억제 + 더 넓은 영역 탐색가능\n",
    "  - 큰 배치는 Gradient 추정이 안정적이지만, Sharp minima로 수렴하거나 일반화가 상대적으로 나쁠 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d502e6a",
   "metadata": {},
   "source": [
    "### [요구사항 3] 테스트 및 submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd5322b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_023859-ka101ee7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/ka101ee7' target=\"_blank\">2025-10-17_02-38-59-act=leakyrelu-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/ka101ee7' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/ka101ee7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, activation='leakyrelu', batch_size=16, epochs=1000)\n",
      "{'epochs': 1000, 'batch_size': 16, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20], 'activation': 'leakyrelu', 'group': 'act_vs_batch'}\n",
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f4f82f0> <torch.utils.data.dataset.Subset object at 0x31f4fa750> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5826, Validation loss 0.6218\n",
      "Epoch 200, Training loss 0.5510, Validation loss 0.5596\n",
      "Epoch 300, Training loss 0.5072, Validation loss 0.5402\n",
      "Epoch 400, Training loss 0.4793, Validation loss 0.5538\n",
      "Epoch 500, Training loss 0.4629, Validation loss 0.4606\n",
      "Epoch 600, Training loss 0.4585, Validation loss 0.4335\n",
      "Epoch 700, Training loss 0.4500, Validation loss 0.4201\n",
      "Epoch 800, Training loss 0.4532, Validation loss 0.5716\n",
      "Epoch 900, Training loss 0.4472, Validation loss 0.5559\n",
      "Epoch 1000, Training loss 0.4342, Validation loss 0.4369\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>██▇▆▆▆▆▅▅▅▄▅▄▄▄▄▃▃▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>Validation loss</td><td>█▇▇▇▇▆▅▆▅▅▅▄▄▄▃▆▃█▃▂▁▂▂▃▁▁▄▂▁▅▃▁▁▄▁▂▂▅▂▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.43417</td></tr><tr><td>Validation loss</td><td>0.43691</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-17_02-38-59-act=leakyrelu-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/ka101ee7' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/ka101ee7</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_023859-ka101ee7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "# 경로 설정 및 데이터셋 로드\n",
    "# Titanic 데이터셋 이진 분류 문제\n",
    "# BASE_PATH를 sys.path에 추가하여 커스텀 모듈 import 가능\n",
    "\n",
    "BASE_PATH = \"/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl\"\n",
    "if BASE_PATH not in sys.path:\n",
    "    sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "# DataLoader 생성 함수\n",
    "# 훈련과 검증 데이터셋을 불러옴\n",
    "# batch_size는 wandb 설정에서 받아옴\n",
    "\n",
    "def get_data():\n",
    "  titanic_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(titanic_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=titanic_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "  return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "# 모델 정의\n",
    "# 입력 : 10개 feature (전처리된 Titanic 데이터셋)\n",
    "# 출력 : 2개 클래스 (사망 / 생존)\n",
    "# 활성화 함수 : wandb.config.activation 사용\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# 모델 및 옵티마이저 생성\n",
    "# optimizer : SGD\n",
    "# loss_fn은 training_loop 내에서 정의하고 있음\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "# 학습 루프\n",
    "# 손실 함수 : CrossEntropyLoss : 타이타닉의 경우 생존, 사망 두가지로 분류되므로 분류 모델 사용\n",
    "# wandb로 학습 과정 로깅\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input = train_batch['input']\n",
    "      target = train_batch['target']\n",
    "\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input = validation_batch['input']\n",
    "        target = validation_batch['target']\n",
    "\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    # wandb 로깅 (+ 비교용 메타 추가)\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": loss_train / num_trains,\n",
    "      \"Validation loss\": loss_validation / num_validations,\n",
    "      \"hparams/activation\": wandb.config.activation,   # ← Facet/Filter/Color 용\n",
    "      \"hparams/batch_size\": wandb.config.batch_size,   # ← Facet/Filter/Color 용\n",
    "    })\n",
    "\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "        f\"Validation loss {loss_validation / num_validations:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "# main 함수\n",
    "# wandb, experiment 초기화\n",
    "# 데이터, 모델, 학습 루프 실행\n",
    "\n",
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [20, 20],\n",
    "    'activation': args.activation,     # ★ 추가: 모델이 참조하는 활성화 함수\n",
    "    'group': 'act_vs_batch',           # ★ 추가: 한 프레임에 묶어보기 위한 그룹명\n",
    "  }\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=\"my_model_training\",\n",
    "    notes=\"Activation x Batch sweep (Titanic)\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=f\"{current_time_str}-act={args.activation}-bs={args.batch_size}\",  # ★ 러닝 구분 쉬움\n",
    "    group=config['group'],                                                 # ★ 같은 그룹으로 묶기\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader, test_data_loader = get_data()\n",
    "\n",
    "  linear_model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  training_loop(\n",
    "    model=linear_model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  in_notebook = \"ipykernel\" in sys.modules\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=in_notebook, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--activation\", type=str, default=\"leakyrelu\",\n",
    "    choices=[\"relu\", \"sigmoid\", \"elu\", \"leakyrelu\"], help=\"Hidden activation function\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=16, help=\"Batch size (int, default: 512)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=1_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args, _ = parser.parse_known_args()\n",
    "\n",
    "  main(args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b298c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl/_04_your_code/homework2/wandb/run-20251017_025516-i1f0lvqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/i1f0lvqc' target=\"_blank\">2025-10-17_02-55-16-act=leakyrelu-bs=16</a></strong> to <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/i1f0lvqc' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/i1f0lvqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, activation='leakyrelu', batch_size=16, epochs=1000)\n",
      "{'epochs': 1000, 'batch_size': 16, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20], 'activation': 'leakyrelu', 'group': 'act_vs_batch'}\n",
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Embarked', 'title', 'family_num', 'alone'],\n",
      "      dtype='object')\n",
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  title  \\\n",
      "0       0.0       3    1  22.0      1      0   7.2500         2      2   \n",
      "1       1.0       1    0  38.0      1      0  71.2833         0      3   \n",
      "2       1.0       3    0  26.0      0      0   7.9250         2      1   \n",
      "3       1.0       1    0  35.0      1      0  53.1000         2      3   \n",
      "4       0.0       3    1  35.0      0      0   8.0500         2      2   \n",
      "5       0.0       3    1  29.0      0      0   8.4583         1      2   \n",
      "6       0.0       1    1  54.0      0      0  51.8625         2      2   \n",
      "7       0.0       3    1   2.0      3      1  21.0750         2      0   \n",
      "8       1.0       3    0  27.0      0      2  11.1333         2      3   \n",
      "9       1.0       2    0  14.0      1      0  30.0708         0      3   \n",
      "\n",
      "   family_num  alone  \n",
      "0           1    0.0  \n",
      "1           1    0.0  \n",
      "2           0    1.0  \n",
      "3           1    0.0  \n",
      "4           0    1.0  \n",
      "5           0    1.0  \n",
      "6           0    1.0  \n",
      "7           4    0.0  \n",
      "8           2    0.0  \n",
      "9           1    0.0  \n",
      "Data Size: 891, Input Shape: torch.Size([891, 10]), Target Shape: torch.Size([891])\n",
      "<torch.utils.data.dataset.Subset object at 0x31f384a10> <torch.utils.data.dataset.Subset object at 0x31f3871d0> Data Size: 418, Input Shape: torch.Size([418, 10])\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5773, Validation loss 0.5473\n",
      "Epoch 200, Training loss 0.5437, Validation loss 0.4984\n",
      "Epoch 300, Training loss 0.5112, Validation loss 0.4721\n",
      "Epoch 400, Training loss 0.4723, Validation loss 0.5727\n",
      "Epoch 500, Training loss 0.4603, Validation loss 0.5537\n",
      "Epoch 600, Training loss 0.4637, Validation loss 0.3968\n",
      "Epoch 700, Training loss 0.4432, Validation loss 0.3828\n",
      "Epoch 800, Training loss 0.4584, Validation loss 0.4058\n",
      "Epoch 900, Training loss 0.4404, Validation loss 0.4137\n",
      "Epoch 1000, Training loss 0.4387, Validation loss 0.3989\n",
      "[Best] epoch=961, val_loss=0.3713 -> saved: best_model.pt\n",
      "✅ Saved: submission.csv (rows=418)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Training loss</td><td>█▇▇▇▆▆▅▅▅▅▅▄▄▄▃▃▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▂▂</td></tr><tr><td>Validation loss</td><td>▅▅▅▅▄▄▅▅▄▅▅▄▄▄▃▆▄▂▃▂▂▇▁▂█▃▂▃▂▁▁▄▁▂▃▂▂▂▁▁</td></tr><tr><td>hparams/batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training loss</td><td>0.43874</td></tr><tr><td>Validation loss</td><td>0.39889</td></tr><tr><td>best_epoch</td><td>961</td></tr><tr><td>best_model_path</td><td>best_model.pt</td></tr><tr><td>best_val_loss</td><td>0.37127</td></tr><tr><td>hparams/activation</td><td>leakyrelu</td></tr><tr><td>hparams/batch_size</td><td>16</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2025-10-17_02-55-16-act=leakyrelu-bs=16</strong> at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/i1f0lvqc' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training/runs/i1f0lvqc</a><br> View project at: <a href='https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training' target=\"_blank\">https://wandb.ai/ff1451-korea-university-of-technology-and-education/my_model_training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251017_025516-i1f0lvqc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "# 경로 설정 및 데이터셋 로드\n",
    "# Titanic 데이터셋 이진 분류 문제\n",
    "# BASE_PATH를 sys.path에 추가하여 커스텀 모듈 import 가능\n",
    "\n",
    "BASE_PATH = \"/Users/leejunyoung/Documents/3-2/deep_Learning/practice/link_dl\"\n",
    "if BASE_PATH not in sys.path:\n",
    "    sys.path.append(BASE_PATH)\n",
    "\n",
    "from _03_homeworks.homework_2.titanic_dataset import get_preprocessed_dataset\n",
    "\n",
    "# DataLoader 생성 함수\n",
    "# 훈련과 검증 데이터셋을 불러옴\n",
    "# batch_size는 wandb 설정에서 받아옴\n",
    "\n",
    "def get_data():\n",
    "  titanic_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "  print(titanic_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "  train_data_loader = DataLoader(dataset=titanic_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "  return train_data_loader, validation_data_loader, test_data_loader\n",
    "\n",
    "# 모델 정의\n",
    "# 입력 : 10개 feature (전처리된 Titanic 데이터셋)\n",
    "# 출력 : 2개 클래스 (사망 / 생존)\n",
    "# 활성화 함수 : wandb.config.activation 사용\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n",
    "\n",
    "# 모델 및 옵티마이저 생성\n",
    "# optimizer : SGD\n",
    "# loss_fn은 training_loop 내에서 정의하고 있음\n",
    "def get_model_and_optimizer():\n",
    "  my_model = MyModel(n_input=10, n_output=2)\n",
    "  optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  return my_model, optimizer\n",
    "\n",
    "# 학습 루프\n",
    "# 손실 함수 : CrossEntropyLoss : 타이타닉의 경우 생존, 사망 두가지로 분류되므로 분류 모델 사용\n",
    "# wandb로 학습 과정 로깅\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "  n_epochs = wandb.config.epochs\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  next_print_epoch = 100\n",
    "\n",
    "  best_val_loss = float(\"inf\")\n",
    "  best_epoch = 0\n",
    "  best_path = \"best_model.pt\"\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    # -------- Train --------\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    num_trains = 0\n",
    "    for train_batch in train_data_loader:\n",
    "      input = train_batch['input']\n",
    "      target = train_batch['target']\n",
    "\n",
    "      output_train = model(input)\n",
    "      loss = loss_fn(output_train, target)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_train += loss.item()\n",
    "      num_trains += 1\n",
    "\n",
    "    # -------- Validate --------\n",
    "    model.eval()\n",
    "    loss_validation = 0.0\n",
    "    num_validations = 0\n",
    "    with torch.no_grad():\n",
    "      for validation_batch in validation_data_loader:\n",
    "        input = validation_batch['input']\n",
    "        target = validation_batch['target']\n",
    "\n",
    "        output_validation = model(input)\n",
    "        loss = loss_fn(output_validation, target)\n",
    "        loss_validation += loss.item()\n",
    "        num_validations += 1\n",
    "\n",
    "    train_loss_avg = loss_train / max(1, num_trains)\n",
    "    val_loss_avg = loss_validation / max(1, num_validations)\n",
    "\n",
    "    # wandb 로깅\n",
    "    wandb.log({\n",
    "      \"Epoch\": epoch,\n",
    "      \"Training loss\": train_loss_avg,\n",
    "      \"Validation loss\": val_loss_avg,\n",
    "      \"hparams/activation\": wandb.config.activation,\n",
    "      \"hparams/batch_size\": wandb.config.batch_size,\n",
    "    })\n",
    "\n",
    "    # 콘솔 출력\n",
    "    if epoch >= next_print_epoch:\n",
    "      print(\n",
    "        f\"Epoch {epoch}, \"\n",
    "        f\"Training loss {train_loss_avg:.4f}, \"\n",
    "        f\"Validation loss {val_loss_avg:.4f}\"\n",
    "      )\n",
    "      next_print_epoch += 100\n",
    "\n",
    "    # -------- Best 체크 & 저장 --------\n",
    "    if val_loss_avg < best_val_loss:\n",
    "      best_val_loss = val_loss_avg\n",
    "      best_epoch = epoch\n",
    "      torch.save(model.state_dict(), best_path)\n",
    "\n",
    "  print(f\"[Best] epoch={best_epoch}, val_loss={best_val_loss:.4f} -> saved: {best_path}\")\n",
    "  wandb.summary[\"best_epoch\"] = best_epoch\n",
    "  wandb.summary[\"best_val_loss\"] = best_val_loss\n",
    "  wandb.summary[\"best_model_path\"] = best_path\n",
    "\n",
    "  return best_epoch, best_val_loss, best_path\n",
    "\n",
    "\n",
    "def predict_on_test(model, test_data_loader):\n",
    "  model.eval()\n",
    "  preds = []\n",
    "  with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "      x = batch[\"input\"]  # 테스트셋은 target이 없다고 가정\n",
    "      logits = model(x)\n",
    "      pred = logits.argmax(dim=1)\n",
    "      preds.extend(pred.tolist())\n",
    "  return preds\n",
    "\n",
    "def write_submission(preds, passenger_ids=None, path=\"submission.csv\"):\n",
    "  if passenger_ids is None:\n",
    "    # 캐글 Titanic 기본 테스트셋 ID 범위(892~1309) 가정\n",
    "    passenger_ids = list(range(892, 892 + len(preds)))\n",
    "  df = pd.DataFrame({\"PassengerId\": passenger_ids, \"Survived\": preds})\n",
    "  df.to_csv(path, index=False)\n",
    "  print(f\"✅ Saved: {path} (rows={len(df)})\")\n",
    "  return path\n",
    "\n",
    "# main 함수\n",
    "# wandb, experiment 초기화\n",
    "# 데이터, 모델, 학습 루프 실행\n",
    "\n",
    "def main(args):\n",
    "  current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args.epochs,\n",
    "    'batch_size': args.batch_size,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_hidden_unit_list': [20, 20],\n",
    "    'activation': args.activation,\n",
    "    'group': 'act_vs_batch',\n",
    "  }\n",
    "\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args.wandb else \"disabled\",\n",
    "    project=\"my_model_training\",\n",
    "    notes=\"Activation x Batch sweep (Titanic)\",\n",
    "    tags=[\"my_model\", \"titanic\"],\n",
    "    name=f\"{current_time_str}-act={args.activation}-bs={args.batch_size}\",\n",
    "    group=config['group'],\n",
    "    config=config\n",
    "  )\n",
    "  print(args)\n",
    "  print(wandb.config)\n",
    "\n",
    "  train_data_loader, validation_data_loader, test_data_loader = get_data()\n",
    "  model, optimizer = get_model_and_optimizer()\n",
    "\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  # ---- 학습 & 베스트 모델 저장 ----\n",
    "  best_epoch, best_val_loss, best_path = training_loop(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_data_loader=train_data_loader,\n",
    "    validation_data_loader=validation_data_loader\n",
    "  )\n",
    "\n",
    "  # ---- 베스트 모델 로드 후 테스트 예측 ----\n",
    "  model.load_state_dict(torch.load(best_path, map_location=\"cpu\"))\n",
    "  preds = predict_on_test(model, test_data_loader)\n",
    "\n",
    "  # ---- submission.csv 생성 ----\n",
    "  sub_path = write_submission(preds, path=\"submission.csv\")\n",
    "  wandb.save(sub_path)\n",
    "\n",
    "  wandb.finish()\n",
    "\n",
    "\n",
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  in_notebook = \"ipykernel\" in sys.modules\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--wandb\", action=argparse.BooleanOptionalAction, default=in_notebook, help=\"True or False\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"--activation\", type=str, default=\"leakyrelu\",\n",
    "    choices=[\"relu\", \"sigmoid\", \"elu\", \"leakyrelu\"], help=\"Hidden activation function\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-b\", \"--batch_size\", type=int, default=16, help=\"Batch size (int, default: 512)\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\n",
    "    \"-e\", \"--epochs\", type=int, default=1_000, help=\"Number of training epochs (int, default:1_000)\"\n",
    "  )\n",
    "\n",
    "  args, _ = parser.parse_known_args()\n",
    "\n",
    "  main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c8409",
   "metadata": {},
   "source": [
    "##### 기술적 고찰\n",
    "- 모델 학습 및 검증 손실 추적\n",
    "  - 1000 epoch 동안 학습을 진행하면서, 각 epoch마다 train loss, validation loss를 확인했다\n",
    "  - 이과정에서 validation loss가 점진적으로 감소하다가 특정 시점이후 다시 증가하는 모습을 보였다\n",
    "  - 이를 통해 과적합이 이루어지고 있다는 것을 확인할 수 있었다\n",
    "\n",
    "- 최적 epoch 탐색\n",
    "  - validation loss가 가장 낮은 epoch를 best_epoch로 지정하고 해당 시점의 모델 가중치를 best_model.pt로 저장했다\n",
    "\n",
    "- Early Stopping 기법을 사용했다면 학습 시간을 단축하면서 동일한 결과를 얻을 수 있었을 것으로 보인다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae05ec",
   "metadata": {},
   "source": [
    "### [요구사항 4] submission.csv 제출 및 등수확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773fdff",
   "metadata": {},
   "source": [
    "![img](https://drive.google.com/thumbnail?id=1FLDAm-hIx0b_szMkLtfqAHbn86MfFoQy&sz=w1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30188f",
   "metadata": {},
   "source": [
    "##### 후기\n",
    "\n",
    "이번 과제를 통해 단순히 모델을 학습시키는 것에서 그치지 않고, 모델의 성능을 객관적으로 평가하고 분석하는 과정의 중요성을 배울 수 있었다. 특히 Validation Loss를 지속적으로 관찰하며 최적의 학습 시점을 스스로 판단하는 경험은 매우 의미 있었다. 학습 초반에는 손실이 점진적으로 감소하다가 일정 시점 이후 다시 증가하는 전형적인 과적합 패턴을 직접 확인할 수 있었고, 이를 통해 단순한 반복 학습만으로는 좋은 결과를 얻을 수 없다는 점을 깨달았다. 또한 최적의 epoch에서 모델 파라미터를 저장하고 이를 기반으로 테스트셋 예측을 진행함으로써 실험의 효율성과 재현성을 확보할 수 있었다.\n",
    "\n",
    "submission.csv를 직접 생성해 Titanic - Machine Learning from Disaster 리더보드에 제출해본 과정은 이론적인 지식을 실제 실습으로 연결하는 경험이었다. 단순한 신경망 구조임에도 불구하고 활성화 함수나 배치 사이즈 같은 작은 설정 변화만으로도 성능에 차이가 발생한다는 점이 특히 흥미로웠다. 결과적으로 이번 과제는 모델의 성능 향상뿐 아니라, 실험을 설계하고 관리하는 과정 또한 데이터 과학에서 매우 중요한 요소임을 체감하게 해주었다. 이런 과정을 통해 단순한 코드 작성에서 한 단계 나아가, 실제 문제 해결을 위한 전략적 접근을 익힐 수 있었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "link_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
